{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,re,sys,subprocess\n",
    "import pysrt\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('video_links_1.csv',encoding='utf-8')\n",
    "links = links.dropna(axis=1, how='all')\n",
    "category = links.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Luxembourg Gardens',\n",
       " 'Buckingham Palace',\n",
       " 'Eiffel Tower',\n",
       " 'Churchill War Rooms',\n",
       " 'Thames Rockets',\n",
       " 'Fat Tire Tours Berlin',\n",
       " \"Musee d'Orsay\",\n",
       " 'National Gallery']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmployeeList =list(links.source_product_name)\n",
    "[str(x) for x in EmployeeList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>source_product_name</th>\n",
       "      <th>city</th>\n",
       "      <th>category</th>\n",
       "      <th>URLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2600006</td>\n",
       "      <td>Luxembourg Gardens</td>\n",
       "      <td>Paris</td>\n",
       "      <td>nature_parks</td>\n",
       "      <td>https://www.youtube.com/watch?v=fQAAMSedWS0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600023</td>\n",
       "      <td>Buckingham Palace</td>\n",
       "      <td>London</td>\n",
       "      <td>nature_parks</td>\n",
       "      <td>https://www.youtube.com/watch?v=T_8kE_JFUhY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500009</td>\n",
       "      <td>Eiffel Tower</td>\n",
       "      <td>Paris</td>\n",
       "      <td>landmarks</td>\n",
       "      <td>https://www.youtube.com/watch?v=pvZRgAZ2g6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2500021</td>\n",
       "      <td>Churchill War Rooms</td>\n",
       "      <td>London</td>\n",
       "      <td>landmarks</td>\n",
       "      <td>https://www.youtube.com/watch?v=bEC-a8CKHJ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2700023</td>\n",
       "      <td>Thames Rockets</td>\n",
       "      <td>London</td>\n",
       "      <td>outdoor_activities</td>\n",
       "      <td>https://www.youtube.com/watch?v=n3xy6sp3iqg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2700011</td>\n",
       "      <td>Fat Tire Tours Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>outdoor_activities</td>\n",
       "      <td>https://www.youtube.com/watch?v=qYKkulHdfHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2800006</td>\n",
       "      <td>Musee d'Orsay</td>\n",
       "      <td>Paris</td>\n",
       "      <td>museum</td>\n",
       "      <td>https://www.youtube.com/watch?v=nwSMOrwH9IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2800021</td>\n",
       "      <td>National Gallery</td>\n",
       "      <td>London</td>\n",
       "      <td>museum</td>\n",
       "      <td>https://www.youtube.com/watch?v=TsSKnRIk0S8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id    source_product_name    city            category  \\\n",
       "0     2600006     Luxembourg Gardens   Paris        nature_parks   \n",
       "1     2600023      Buckingham Palace  London        nature_parks   \n",
       "2     2500009           Eiffel Tower   Paris           landmarks   \n",
       "3     2500021    Churchill War Rooms  London           landmarks   \n",
       "4     2700023         Thames Rockets  London  outdoor_activities   \n",
       "5     2700011  Fat Tire Tours Berlin  Berlin  outdoor_activities   \n",
       "6     2800006          Musee d'Orsay   Paris              museum   \n",
       "7     2800021       National Gallery  London              museum   \n",
       "\n",
       "                                          URLS  \n",
       "0  https://www.youtube.com/watch?v=fQAAMSedWS0  \n",
       "1  https://www.youtube.com/watch?v=T_8kE_JFUhY  \n",
       "2  https://www.youtube.com/watch?v=pvZRgAZ2g6c  \n",
       "3  https://www.youtube.com/watch?v=bEC-a8CKHJ8  \n",
       "4  https://www.youtube.com/watch?v=n3xy6sp3iqg  \n",
       "5  https://www.youtube.com/watch?v=qYKkulHdfHY  \n",
       "6  https://www.youtube.com/watch?v=nwSMOrwH9IA  \n",
       "7  https://www.youtube.com/watch?v=TsSKnRIk0S8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for c in category:\n",
    "    t = links[links.category == c]\n",
    "    for row in t.to_dict('records'):\n",
    "        filename = str(row['product_id'])+'_'+row['URLS'].split('=')[-1]+'.en.srt'\n",
    "        file_clean = filename.split('.srt')[0]+'_cleaned.srt'\n",
    "        if not os.path.exists(file_clean):\n",
    "            print \"not\"\n",
    "            text = \"\"\n",
    "            command =\"youtube-dl -o \"+str(row['product_id'])+'_'+row['URLS'].split('=')[-1]+\".mp4 --sub-format vtt --convert-subs srt --write-auto-sub --sub-lang en -f mp4 \"+str(row['URLS']).strip()\n",
    "            subprocess.call(command, shell=True)\n",
    "            subs = pysrt.open(filename, encoding='iso-8859-1')\n",
    "            f =open(file_clean,'a+')\n",
    "            j=0\n",
    "            row['start_time'] = subs[0].start\n",
    "            for i in range(0,len(subs)):\n",
    "                if i%2 !=0:\n",
    "                    text = text+subs[i].text+\" \"\n",
    "                    print >> f,j\n",
    "                    print >> f,subs[i-1].start,' --> ',subs[i-1].end\n",
    "                    print >> f,subs[i].text,'\\n'\n",
    "                    j =j +1\n",
    "            os.remove(filename)\n",
    "            f.close()\n",
    "        else:\n",
    "            print \"yes\"\n",
    "            text =\"\"\n",
    "            subs = pysrt.open(file_clean, encoding='iso-8859-1')\n",
    "            for i in range(0,len(subs)):\n",
    "                text = text+subs[i].text+\" \"\n",
    "\n",
    "            row['start_time'] = subs[0].start \n",
    "        row['end_time'] = subs[len(subs)-1].end\n",
    "        row['review_text'] = text \n",
    "        row['source'] = 7\n",
    "        row['source_product_id'] = row['product_id']\n",
    "        row['source_review_id'] = row['URLS'].split('=')[-1]\n",
    "        out.append(row)\n",
    "    video_review = pd.DataFrame(out)\n",
    "    video_review=video_review.rename(index=str, columns={\"source_product_name\": \"product_name\",\"URLS\": \"review_url\"})\n",
    "    video_review['review_date'] = \"\"\n",
    "    video_review['star_rating'] = 5\n",
    "    video_review['verified_user']=\"\"\n",
    "    video_review['reviewer_name']=\"\"\n",
    "    video_review['review_url']=video_review['review_url']\n",
    "    video_review['review_tag']=\"\"\n",
    "    col = ['source','source_review_id','source_product_id','product_name','review_date','star_rating','verified_user','reviewer_name','review_url','review_tag','review_text']\n",
    "    video_review.to_csv(c+'_source_video_reviews.txt',sep='~',quoting=csv.QUOTE_NONE,encoding='utf-8',index=False,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_snip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from itertools import *\n",
    "file =sys.argv[1]\n",
    "video_snip = pd.read_csv(file,sep='~')\n",
    "c = file.split('_')[3]\n",
    "ids= video_snip.source_product_id.unique()\n",
    "timing_output=[]\n",
    "flag=0\n",
    "t1=\"\"\n",
    "t2=\"\"\n",
    "t3=\"\"\n",
    "t4=\"\"\n",
    "t5=\"\"\n",
    "for id in ids:\n",
    "    temp = video_snip[video_snip.source_product_id == id]\n",
    "    for row in temp.to_dict('records'):\n",
    "        x=\"\"\n",
    "        row['video_start_time'] = str(subs[0].start).split(',')[0]\n",
    "        subs = pysrt.open(c+'_'+str(id)+'_'+row['source_review_id'].split('=')[-1]+'.en_cleaned.srt', encoding='iso-8859-1')\n",
    "        for i in range(0,len(subs)):\n",
    "            subs[i].text = subs[i].text.lower().replace('-',' ')\n",
    "            subs[i].text = re.sub(r'([^\\s\\w]|_)+', '',subs[i].text )\n",
    "            row['sentiment_text'] = row['sentiment_text'].lower()\n",
    "            row['sentiment_text'] = re.sub(r'([^\\s\\w]|_)+', '',row['sentiment_text'] )\n",
    "            if row['sentiment_text'] in subs[i].text:\n",
    "                row['start_time'] = str(subs[i-1].start).split(',')[0]\n",
    "                row['end_time'] = str(subs[i].end).split(',')[0]\n",
    "                x = subs[i].text\n",
    "            else:\n",
    "               # row['snippet_end_time'] = subs[i].end \n",
    "                if i-1 >=0:\n",
    "                    t1 = subs[i-1].text+\" \"+subs[i].text\n",
    "                if i-2 >=0:\n",
    "                    t4 = subs[i-2].text+\" \"+subs[i-1].text+\" \"+subs[i].text\n",
    "                if (i+1) < len(subs):\n",
    "                    t2 = subs[i].text+\" \"+subs[i+1].text\n",
    "                if (i+2) < len(subs):\n",
    "                    t3 = subs[i].text+\" \"+subs[i+1].text+\" \"+subs[i+2].text\n",
    "                if (i+3) < len(subs):\n",
    "                    t5 = subs[i].text+\" \"+subs[i+1].text+\" \"+subs[i+2].text+\" \"+subs[i+3].text\n",
    "\n",
    "                if row['sentiment_text'] in t1:\n",
    "                    row['start_time'] = str(subs[i-1].start).split(',')[0]\n",
    "                    row['end_time'] = str(subs[i].end).split(',')[0]\n",
    "                    break\n",
    "                elif row['sentiment_text'] in t2:\n",
    "                    row['start_time'] = str(subs[i].start).split(',')[0]\n",
    "                    row['end_time'] = str(subs[i+1].end).split(',')[0]\n",
    "                    break\n",
    "                elif row['sentiment_text'] in t3:\n",
    "                    if (i+2) < len(subs):\n",
    "                        row['start_time'] = str(subs[i].start).split(',')[0]\n",
    "                        row['end_time'] = str(subs[i+2].end).split(',')[0]\n",
    "                        break\n",
    "                elif row['sentiment_text'] in t4:\n",
    "                    row['start_time'] = str(subs[i-2].start).split(',')[0]\n",
    "                    row['end_time'] = str(subs[i].end).split(',')[0]\n",
    "                    break\n",
    "                elif row['sentiment_text'] in t5:\n",
    "                    row['start_time'] = str(subs[i].start).split(',')[0]\n",
    "                    row['end_time'] = str(subs[i+3].end).split(',')[0]\n",
    "                    break\n",
    "        row['video_end_time'] = str(subs[len(subs)-1].end).split(',')[0]\n",
    "        timing_output.append(row)\n",
    "        row[\"sentiment_text_start_index\"]=row['start_index']\n",
    "        row[\"sentiment_text_end_index\"]=row['end_index']\n",
    "        row['snippet_length'] = (len(row[\"sentiment_text\"]))\n",
    "        \n",
    "timing_output = pd.DataFrame(timing_output)                \n",
    "timing_output['source_id'] = 7\n",
    "timing_output=timing_output.rename(index=str, columns={\"category\": \"category_id\", \"source_product_id\": \"product_id\",'confidence-score':\"sentiment_conf_score\"})\n",
    "COLS= ['product_id','category_id','source_id','source_review_id','video_review_id','category_aspect_id','aspect','sentiment_type','sentiment_text','sentiment_text_start_index','sentiment_text_end_index','sentiment_start_snippet','sentiment_end_snippet','treemap_name','sentiment_conf_score','end_time','start_time']\n",
    "timing_output.to_csv(c+'_product_video_review_sentiment.csv',index=False,columns=COLS)\n",
    "snipp = timing_output[['source_review_id','start_time','end_time','video_end_time','video_start_time','sentiment_text','snippet_length','source_id','product_id']]\n",
    "snipp = snipp.rename(index=str, columns={\"source_review_id\": \"video_loc\", \"sentiment_text\": \"snippet\"})\n",
    "col = ['id','video_loc','start_time','end_time','snippet','snippet_length']\n",
    "snipp.to_csv(c+'_product_video_review_snippet.csv',index=False,columns=col)\n",
    "colum =['id','product_id','video_loc','source_id','overall_rating','outof_rating','review_date','normalized_date','source_review_id','reviewer','review_title','review_url','video_url','review_text','video_review_text','start_time','end_time','priority','status']\n",
    "vid_rev = snipp[['video_loc','video_end_time','video_start_time','source_id','product_id']]\n",
    "vid_rev = vid_rev.rename(index=str, columns={\"video_end_time\": \"end_time\", \"video_start_time\": \"start_time\"})\n",
    "vid_rev = vid_rev.drop_duplicates()\n",
    "vid_rev['status']= 'A'\n",
    "vid_rev.to_csv(c+'_product_video_review.csv',index=False,columns=colum)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_output=timing_output.rename(index=str, columns={\"category\": \"category_id\", \"source_product_id\": \"product_id\",'confidence-score':\"sentiment_conf_score\"})\n",
    "COLS= ['product_id','category_id','source_id','source_review_id','video_review_id','category_aspect_id','aspect','sentiment_type','sentiment_text','sentiment_text_start_index','sentiment_text_end_index','sentiment_start_snippet','sentiment_end_snippet','treemap_name','sentiment_conf_score','end_time','start_time']\n",
    "timing_output.to_csv('product_video_review_sentiment.csv',index=False,columns=COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snipp = timing_output[['source_review_id','start_time','end_time','video_end_time','video_start_time','sentiment_text','snippet_length','source_id','product_id']]\n",
    "snipp = snipp.rename(index=str, columns={\"source_review_id\": \"video_loc\", \"sentiment_text\": \"snippet\"})\n",
    "col = ['id','video_loc','start_time','end_time','snippet','snippet_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snipp.to_csv('product_video_review_snippet.csv',index=False,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum =['id','product_id','video_loc','source_id','overall_rating','outof_rating','review_date','normalized_date','source_review_id','reviewer','review_title','review_url','video_url','review_text','video_review_text','start_time','end_time','priority','status']\n",
    "vid_rev = snipp[['video_loc','video_end_time','video_start_time','source_id','product_id']]\n",
    "vid_rev = vid_rev.rename(index=str, columns={\"video_end_time\": \"end_time\", \"video_start_time\": \"start_time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_rev = vid_rev.drop_duplicates()\n",
    "vid_rev['status']= 'A'\n",
    "vid_rev.to_csv('product_video_review.csv',index=False,columns=colum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('lanmarks_video_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "x.to_csv('landmarks_video_reviews.txt',sep='~',quoting=csv.QUOTE_NONE,encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
